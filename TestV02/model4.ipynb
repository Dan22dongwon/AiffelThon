{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9ed8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 및 모듈 임포트\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60eda96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능\n",
      "사용 중인 CUDA 장치 개수: 1\n",
      "현재 사용 중인 CUDA 장치: 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA 사용 가능\")\n",
    "    print(\"사용 중인 CUDA 장치 개수:\", torch.cuda.device_count())\n",
    "    print(\"현재 사용 중인 CUDA 장치:\", torch.cuda.current_device())\n",
    "else:\n",
    "    print(\"CUDA 사용 불가능\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af85d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "hyper_param_batch = 2\n",
    "\n",
    "# 난수 시드 설정\n",
    "random_seed = 100\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# 클래스 개수 및 사용할 모델 이름 설정\n",
    "num_classes = 4\n",
    "model_name = 'efficientnet-b7'\n",
    "\n",
    "train_name = 'model4'\n",
    "\n",
    "# 모델 및 데이터 경로 설정\n",
    "PATH = '/aiffel/aiffel/team_project/model4/scalp_weights/'\n",
    "\n",
    "# data_train_path = './train_data/'+train_name+'/train'\n",
    "# data_validation_path = './train_data/'+train_name+'/validation'\n",
    "\n",
    "data_train_path = '/aiffel/aiffel/team_project/'+train_name+'/train'\n",
    "data_validation_path = '/aiffel/aiffel/team_project/'+train_name+'/validation'\n",
    "data_test_path = '/aiffel/aiffel/team_project/'+train_name+'/test'\n",
    "\n",
    "# EfficientNet 모델의 입력 이미지 크기 확인 및 출력\n",
    "image_size = EfficientNet.get_image_size(model_name)\n",
    "print(image_size)\n",
    "\n",
    "# 미리 학습된 EfficientNet 모델 로드\n",
    "model = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n",
    "model = model.to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4e3c90f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size : 2,  train/val : 3750 / 1070\n",
      "['0', '1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 데이터 전처리를 위한 변환 정의\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize([int(600), int(600)], interpolation=4),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.Lambda(lambda x: x.rotate(90)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize([int(600), int(600)], interpolation=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return filename.lower().endswith(('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp'))\n",
    "\n",
    "def is_valid_folder(foldername):\n",
    "    return foldername != '.ipynb_checkpoints'\n",
    "\n",
    "# 데이터셋 로드\n",
    "train_data_set = datasets.ImageFolder(data_train_path, transform=transforms_train)\n",
    "val_data_set = datasets.ImageFolder(data_validation_path, transform=transforms_val, is_valid_file=is_image_file)\n",
    "\n",
    "\n",
    "# 데이터 로더 설정\n",
    "dataloaders, batch_num = {}, {}\n",
    "dataloaders['train'] = DataLoader(train_data_set, batch_size=hyper_param_batch, shuffle=True, num_workers=1)\n",
    "dataloaders['val'] = DataLoader(val_data_set, batch_size=hyper_param_batch, shuffle=False, num_workers=1)\n",
    "batch_num['train'], batch_num['val'] = len(train_data_set), len(val_data_set)\n",
    "\n",
    "# 배치 크기 및 데이터셋 크기 출력\n",
    "print('batch_size : %d,  train/val : %d / %d' % (hyper_param_batch, batch_num['train'], batch_num['val']))\n",
    "\n",
    "# 클래스 이름 출력\n",
    "class_names = train_data_set.classes\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d88c3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.best_model_wts = None  # 최적의 모델 가중치 저장 변수\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "\n",
    "    # 모델 저장은 train_model 함수에서 처리\n",
    "\n",
    "# train_model 함수의 코드는 상기 설명에 따라 수정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "469ec5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, early_stopping, num_epochs=25):\n",
    "    start_time = time.time()\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        if len(val_loss) != 0:\n",
    "            best_val_loss = min(val_loss)\n",
    "            early_stopping(best_val_loss, model)\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        epoch_start = time.time()\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            num_cnt = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                num_cnt += len(labels)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = float(running_loss / num_cnt)\n",
    "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "            else:\n",
    "                val_loss.append(epoch_loss)\n",
    "                val_acc.append(epoch_acc)\n",
    "                \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "                \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_idx = epoch\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
    "                \n",
    "            epoch_end = time.time() - epoch_start\n",
    "            print('Training epochs {} in {:.0f}m {:.0f}s'.format(epoch, epoch_end // 60, epoch_end % 60))\n",
    "            print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    torch.save(model, PATH + 'aram_'+train_name+'.pt')\n",
    "    torch.save(model.state_dict(), PATH + 'president_aram_'+train_name+'.pt')\n",
    "    print('model saved')\n",
    "\n",
    "    end_sec = time.time() - start_time\n",
    "    end_times = str(datetime.timedelta(seconds=end_sec)).split('.')\n",
    "    end_time = end_times[0]\n",
    "    print(\"end time :\", end_time)\n",
    "    \n",
    "    return model, best_idx, best_acc, train_loss, train_acc, val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cefa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.9389 Acc: 62.0267\n",
      "Training epochs 0 in 22m 24s\n",
      "\n",
      "val Loss: 0.9564 Acc: 56.1682\n",
      "==> best model saved - 0 / 56.2\n",
      "Training epochs 0 in 24m 4s\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.7955 Acc: 67.3867\n",
      "Training epochs 1 in 22m 24s\n",
      "\n",
      "val Loss: 0.7720 Acc: 72.1495\n",
      "==> best model saved - 1 / 72.1\n",
      "Training epochs 1 in 24m 4s\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "val Loss: 0.8515 Acc: 71.7757\n",
      "Training epochs 2 in 24m 5s\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.6859 Acc: 71.6267\n",
      "Training epochs 3 in 22m 24s\n",
      "\n",
      "val Loss: 0.9863 Acc: 65.1402\n",
      "Training epochs 3 in 24m 4s\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.6483 Acc: 73.2533\n",
      "Training epochs 4 in 22m 26s\n",
      "\n",
      "val Loss: 0.8860 Acc: 66.8224\n",
      "Training epochs 4 in 24m 6s\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.6127 Acc: 74.7200\n",
      "Training epochs 5 in 22m 26s\n",
      "\n",
      "val Loss: 1.0138 Acc: 66.4486\n",
      "Training epochs 5 in 24m 6s\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.5859 Acc: 76.5867\n",
      "Training epochs 6 in 22m 25s\n",
      "\n",
      "val Loss: 0.8810 Acc: 69.1589\n",
      "Training epochs 6 in 24m 5s\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.5111 Acc: 78.9600\n",
      "Training epochs 7 in 22m 26s\n",
      "\n",
      "val Loss: 0.7448 Acc: 70.5607\n",
      "Training epochs 7 in 24m 6s\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.4727 Acc: 81.2533\n",
      "Training epochs 8 in 22m 24s\n",
      "\n",
      "val Loss: 0.8641 Acc: 68.5981\n",
      "Training epochs 8 in 24m 4s\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.4507 Acc: 82.0800\n",
      "Training epochs 9 in 22m 22s\n",
      "\n",
      "val Loss: 0.8689 Acc: 67.4766\n",
      "Training epochs 9 in 24m 2s\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.4238 Acc: 83.6800\n",
      "Training epochs 10 in 22m 19s\n",
      "\n",
      "val Loss: 0.8261 Acc: 69.8131\n",
      "Training epochs 10 in 23m 59s\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.4140 Acc: 84.0000\n",
      "Training epochs 11 in 22m 19s\n",
      "\n",
      "val Loss: 0.9440 Acc: 67.9439\n",
      "Training epochs 11 in 23m 59s\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.3965 Acc: 84.0000\n",
      "Training epochs 12 in 22m 19s\n",
      "\n",
      "val Loss: 0.8993 Acc: 69.3458\n",
      "Training epochs 12 in 23m 59s\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.3689 Acc: 86.3733\n",
      "Training epochs 13 in 22m 20s\n",
      "\n",
      "val Loss: 0.9664 Acc: 67.5701\n",
      "Training epochs 13 in 23m 60s\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.3528 Acc: 86.8533\n",
      "Training epochs 14 in 22m 24s\n",
      "\n",
      "val Loss: 1.0028 Acc: 67.6636\n",
      "Training epochs 14 in 24m 3s\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.3446 Acc: 87.2000\n",
      "Training epochs 15 in 22m 25s\n",
      "\n",
      "val Loss: 0.9556 Acc: 68.8785\n",
      "Training epochs 15 in 24m 4s\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.3451 Acc: 86.8267\n",
      "Training epochs 16 in 22m 25s\n",
      "\n",
      "val Loss: 0.9478 Acc: 69.0654\n",
      "Training epochs 16 in 24m 4s\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.3473 Acc: 86.4000\n",
      "Training epochs 17 in 22m 24s\n",
      "\n",
      "val Loss: 0.9833 Acc: 67.4766\n",
      "Training epochs 17 in 24m 3s\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.3414 Acc: 87.0933\n",
      "Training epochs 18 in 22m 26s\n",
      "\n",
      "val Loss: 0.9706 Acc: 68.3178\n",
      "Training epochs 18 in 24m 6s\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.3433 Acc: 86.6667\n",
      "Training epochs 19 in 22m 24s\n",
      "\n",
      "val Loss: 0.9767 Acc: 68.4112\n",
      "Training epochs 19 in 24m 4s\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.3446 Acc: 86.9600\n",
      "Training epochs 20 in 22m 25s\n",
      "\n",
      "val Loss: 0.9821 Acc: 67.4766\n",
      "Training epochs 20 in 24m 5s\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.3370 Acc: 86.7200\n",
      "Training epochs 21 in 22m 21s\n",
      "\n",
      "val Loss: 0.9978 Acc: 66.6355\n",
      "Training epochs 21 in 23m 60s\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.3404 Acc: 87.3600\n",
      "Training epochs 22 in 22m 24s\n",
      "\n",
      "val Loss: 0.9762 Acc: 67.7570\n",
      "Training epochs 22 in 24m 4s\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.3407 Acc: 87.2000\n",
      "Training epochs 23 in 22m 24s\n",
      "\n",
      "val Loss: 0.9838 Acc: 67.6636\n",
      "Training epochs 23 in 24m 4s\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.3402 Acc: 87.0667\n",
      "Training epochs 24 in 22m 23s\n",
      "\n",
      "val Loss: 0.9741 Acc: 68.1308\n",
      "Training epochs 24 in 24m 3s\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 손실 함수 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습률 스케줄러 설정\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "# 학습 수행 횟수 설정 및 학습 함수 호출\n",
    "num_epochs = 30\n",
    "train_model(model, criterion, optimizer_ft, ex\n",
    "            p_lr_scheduler,early_stopping, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba2a6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
